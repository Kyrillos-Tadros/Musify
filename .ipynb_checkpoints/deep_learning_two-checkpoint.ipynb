{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_process_dataset_mix import process_dataset\n",
    "\n",
    "\n",
    "devided_data_folder = 'devided_data'  \n",
    "images_data_folder = 'images_data_mix'  \n",
    "\n",
    "# Call the function\n",
    "process_dataset(devided_data_folder, images_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 23:00:26.049815: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-06 23:00:26.049920: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-06 23:00:26.152893: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-06 23:00:26.345309: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 23:00:28.476168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers, optimizers, callbacks\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directories\n",
    "train_dir = 'images_data_mix/Train'\n",
    "val_dir = 'images_data_mix/Validation'\n",
    "test_dir = 'images_data_mix/Test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 448, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "img = load_img('images_data_mix/Train/blues/blues.00001_spectral_contrast.png')\n",
    "x = img_to_array(img)/255  # We divide the pixel value by 255 to end up between 0 and 1\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Rescaling(1./255, input_shape = (448, 448, 3)))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(filters = 32, kernel_size = (3,3), activation=\"relu\", padding = \"same\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), padding = \"same\") )\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(filters = 64, kernel_size = (3,3), activation=\"relu\", padding = \"same\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), padding = \"same\") )\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(filters = 128, kernel_size = (3,3), activation=\"relu\", padding = \"same\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), padding = \"same\") )\n",
    "\n",
    "model.add(layers.Conv2D(filters = 256, kernel_size = (3,3), activation=\"relu\", padding = \"same\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), padding = \"same\") )\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Here we flatten our data to end up with just one dimension\n",
    "\n",
    "model.add(layers.Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adam = optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2800 files belonging to 10 classes.\n",
      "Found 600 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = image_dataset_from_directory(\n",
    "  train_dir, # Folder directory \n",
    "  labels = \"inferred\", # inferred from\n",
    "  label_mode = \"categorical\",\n",
    "  seed=123,\n",
    "  image_size=(448, 448),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "# We define a second one for the test data\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "  val_dir,\n",
    "  labels = \"inferred\",\n",
    "  label_mode = \"categorical\",\n",
    "  seed=123,\n",
    "  image_size=(448, 448),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MODEL = \"model_1\"\n",
    "\n",
    "#This callback will save the model to a file after every epoch.\n",
    "modelCheckpooint = callbacks.ModelCheckpoint(\"{}.keras\".format(MODEL), monitor=\"val_loss\", verbose=0, save_best_only=True)\n",
    "\n",
    "#This callback reduces the learning rate when a metric has stopped improving.\n",
    "LRreducer = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor = 0.1, patience=3, verbose=1, min_lr=0)\n",
    "\n",
    "#This callback will stop the training if the monitored metric (in this case, validation loss) does not improve.\n",
    "EarlyStopper = callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 23:01:13.418528: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n",
      "2024-05-06 23:01:17.463182: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/88 [..............................] - ETA: 11:36 - loss: 2.3196 - accuracy: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 23:01:19.376526: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n",
      "2024-05-06 23:01:23.488065: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2/88 [..............................] - ETA: 8:27 - loss: 9.3342 - accuracy: 0.1406 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 23:01:25.262506: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/88 [=>............................] - ETA: 8:09 - loss: 4.9804 - accuracy: 0.1384"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=100,\n",
    "        validation_data=val_ds,\n",
    "        callbacks = [modelCheckpooint, LRreducer, EarlyStopper])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lewagon)",
   "language": "python",
   "name": "lewagon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

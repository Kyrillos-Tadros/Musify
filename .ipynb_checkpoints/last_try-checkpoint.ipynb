{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 10:02:17.176901: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-22 10:02:17.176987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-22 10:02:17.178393: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-22 10:02:17.191227: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-22 10:02:18.885207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler ,RobustScaler ,PowerTransformer ,QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Deep learning libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Statistical distributions for randomized search\n",
    "from scipy.stats import loguniform, randint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('combined_csv/train_data.csv')\n",
    "test = pd.read_csv('combined_csv/test_data.csv')\n",
    "val = pd.read_csv('combined_csv/val_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('genre', axis=1)\n",
    "X_test = test.drop('genre', axis=1)\n",
    "X_val = val.drop('genre', axis=1)\n",
    "y_train = train.genre\n",
    "y_test = test.genre\n",
    "y_val = val.genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = labelencoder.fit_transform(y_train)\n",
    "y_test_encoded = labelencoder.transform(y_test)\n",
    "y_val_encoded = labelencoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names that contain \"_var\"\n",
    "var_columns = [col for col in X_train.columns if col.endswith(\"_var\")]\n",
    "\n",
    "X_train[var_columns] = np.sqrt(X_train[var_columns])\n",
    "X_test[var_columns] = np.sqrt(X_test[var_columns])\n",
    "X_val[var_columns] = np.sqrt(X_val[var_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 18s]\n",
      "val_accuracy: 0.1812080591917038\n",
      "\n",
      "Best val_accuracy So Far: 0.7516778707504272\n",
      "Total elapsed time: 00h 17m 59s\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 1s 16ms/step - loss: 1.7028 - accuracy: 0.7167 - val_loss: 1.7510 - val_accuracy: 0.7114\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6587 - accuracy: 0.7225 - val_loss: 1.7530 - val_accuracy: 0.6644\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6316 - accuracy: 0.7310 - val_loss: 1.7829 - val_accuracy: 0.7114\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.5776 - accuracy: 0.7296 - val_loss: 1.6839 - val_accuracy: 0.7450\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6226 - accuracy: 0.7210 - val_loss: 1.7389 - val_accuracy: 0.7047\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6940 - accuracy: 0.7024 - val_loss: 1.7850 - val_accuracy: 0.6980\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6057 - accuracy: 0.7325 - val_loss: 1.7156 - val_accuracy: 0.7248\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1.6119 - accuracy: 0.7439 - val_loss: 1.7685 - val_accuracy: 0.6846\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6334 - accuracy: 0.7353 - val_loss: 1.7780 - val_accuracy: 0.6577\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6387 - accuracy: 0.7082 - val_loss: 1.7398 - val_accuracy: 0.6913\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6518 - accuracy: 0.7167 - val_loss: 1.7359 - val_accuracy: 0.7181\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.7272 - accuracy: 0.7139 - val_loss: 1.7879 - val_accuracy: 0.6779\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6607 - accuracy: 0.7196 - val_loss: 1.7000 - val_accuracy: 0.7181\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6076 - accuracy: 0.7210 - val_loss: 1.7344 - val_accuracy: 0.6913\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6106 - accuracy: 0.6953 - val_loss: 1.8162 - val_accuracy: 0.6779\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.7106 - accuracy: 0.7010 - val_loss: 1.7941 - val_accuracy: 0.6913\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6843 - accuracy: 0.7110 - val_loss: 1.8345 - val_accuracy: 0.6644\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6551 - accuracy: 0.7153 - val_loss: 1.7472 - val_accuracy: 0.7181\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6749 - accuracy: 0.6981 - val_loss: 1.8520 - val_accuracy: 0.6040\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.7028 - accuracy: 0.6996 - val_loss: 1.7438 - val_accuracy: 0.7450\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.5815 - accuracy: 0.7253 - val_loss: 1.6978 - val_accuracy: 0.6913\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.5725 - accuracy: 0.7382 - val_loss: 1.8223 - val_accuracy: 0.6644\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6223 - accuracy: 0.7239 - val_loss: 1.6689 - val_accuracy: 0.7181\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.5695 - accuracy: 0.7339 - val_loss: 1.6626 - val_accuracy: 0.7047\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6495 - accuracy: 0.7139 - val_loss: 1.7728 - val_accuracy: 0.6980\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6859 - accuracy: 0.7067 - val_loss: 1.7988 - val_accuracy: 0.6846\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6652 - accuracy: 0.7139 - val_loss: 1.7235 - val_accuracy: 0.7047\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6159 - accuracy: 0.7296 - val_loss: 1.7520 - val_accuracy: 0.7047\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6133 - accuracy: 0.7296 - val_loss: 1.7877 - val_accuracy: 0.6376\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6840 - accuracy: 0.6938 - val_loss: 1.9675 - val_accuracy: 0.6242\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6996 - accuracy: 0.7210 - val_loss: 1.7853 - val_accuracy: 0.6577\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6291 - accuracy: 0.7282 - val_loss: 1.8530 - val_accuracy: 0.6443\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1.6123 - accuracy: 0.7282 - val_loss: 1.8505 - val_accuracy: 0.6711\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6585 - accuracy: 0.7368 - val_loss: 1.9710 - val_accuracy: 0.6443\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.5909 - accuracy: 0.7425 - val_loss: 1.7363 - val_accuracy: 0.6980\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.5978 - accuracy: 0.7496 - val_loss: 1.7722 - val_accuracy: 0.6779\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.5773 - accuracy: 0.7382 - val_loss: 1.8098 - val_accuracy: 0.6779\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6632 - accuracy: 0.7039 - val_loss: 1.8518 - val_accuracy: 0.6577\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.7119 - accuracy: 0.7053 - val_loss: 1.8348 - val_accuracy: 0.6913\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6914 - accuracy: 0.6881 - val_loss: 1.7405 - val_accuracy: 0.7315\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.5797 - accuracy: 0.7253 - val_loss: 1.8155 - val_accuracy: 0.6711\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6639 - accuracy: 0.7239 - val_loss: 1.8675 - val_accuracy: 0.6711\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.6381 - accuracy: 0.7468 - val_loss: 1.7641 - val_accuracy: 0.6913\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.5876 - accuracy: 0.7425 - val_loss: 1.8011 - val_accuracy: 0.6711\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Training accuracy: 0.7424892783164978\n",
      "Validation accuracy: 0.6711409687995911\n",
      "Test accuracy: 0.7218543046357616\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the model building function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 6)):\n",
    "        model.add(Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=128, step=32),\n",
    "                        activation='relu',\n",
    "                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01),  # Add L1 and L2 regularization\n",
    "                        input_dim=X_train.shape[1] if i==0 else None))  # Only the first layer needs input_dim\n",
    "        model.add(Dropout(hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=len(np.unique(y_train_encoded)), activation='softmax'))\n",
    "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=100,\n",
    "                     project_name='my_project')\n",
    "\n",
    "# Perform hyperparameter search\n",
    "tuner.search(X_train_scaled, y_train_encoded,\n",
    "             validation_data=(X_val_scaled, y_val_encoded))\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Add EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20)  # Increase patience\n",
    "\n",
    "# Fit the best model\n",
    "history = best_model.fit(X_train_scaled, y_train_encoded, epochs=100, batch_size=32, verbose=1, \n",
    "               validation_data=(X_val_scaled, y_val_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Retrieve training and validation accuracy\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = accuracy_score(y_test_encoded, y_pred_labels)\n",
    "\n",
    "# Print accuracies\n",
    "print('Training accuracy:', train_accuracy)\n",
    "print('Validation accuracy:', val_accuracy)\n",
    "print('Test accuracy:', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 97206, done.\u001b[K\n",
      "remote: Counting objects: 100% (486/486), done.\u001b[K\n",
      "remote: Compressing objects: 100% (228/228), done.\u001b[K\n",
      "remote: Total 97206 (delta 283), reused 423 (delta 254), pack-reused 96720\u001b[K\n",
      "Receiving objects: 100% (97206/97206), 612.89 MiB | 1.22 MiB/s, done.\n",
      "Resolving deltas: 100% (70701/70701), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kyrillos/code/Kyrillos-Tadros/musify\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  277M  100  277M    0     0  1066k      0  0:04:26  0:04:26 --:--:--  998k 1020k      0  0:04:38  0:00:12  0:04:26 1097k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 73020  100 73020    0     0   140k      0 --:--:-- --:--:-- --:--:--  140k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
    "!curl -O https://storage.googleapis.com/audioset/vggish_pca_params.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 08:56:01.528850: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-27 08:56:01.528932: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-27 08:56:01.630318: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-27 08:56:01.843204: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-27 08:56:03.805629: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/kyrillos/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/kyrillos/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/kyrillos/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/kyrillos/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/home/kyrillos/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/kyrillos/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"vgg19\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(32, 1249, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(feature\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(features)\n\u001b[0;32m---> 48\u001b[0m X_train_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvggish_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m X_test_features \u001b[38;5;241m=\u001b[39m extract_features(X_test, vggish_model)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Define the model architecture\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [1], line 44\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(audio_data, model, sr)\u001b[0m\n\u001b[1;32m     42\u001b[0m     melspec \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmelspectrogram(y\u001b[38;5;241m=\u001b[39msignal, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[1;32m     43\u001b[0m     melspec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(melspec, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m     feature \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmelspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(feature\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(features)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileyy16meet.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/kyrillos/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/kyrillos/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/kyrillos/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/kyrillos/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/home/kyrillos/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/kyrillos/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"vgg19\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(32, 1249, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "# Load the GTZAN dataset\n",
    "def load_gtzan_dataset(data_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    genres = os.listdir(data_path)\n",
    "    for genre in genres:\n",
    "        genre_path = os.path.join(data_path, genre)\n",
    "        for audio_file in os.listdir(genre_path):\n",
    "            audio_path = os.path.join(genre_path, audio_file)\n",
    "            signal, sr = librosa.load(audio_path)\n",
    "            X.append(signal)\n",
    "            y.append(genres.index(genre))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load the GTZAN dataset\n",
    "X, y = load_gtzan_dataset('Segmented_files')  # Replace with the path to your audio files\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = len(np.unique(y))\n",
    "y = to_categorical(y, num_classes)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the pre-trained VGGish model\n",
    "vggish_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Extract features from the audio files using the pre-trained model\n",
    "def extract_features(audio_data, model, sr=22050):\n",
    "    features = []\n",
    "    for signal in audio_data:\n",
    "        melspec = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "        melspec = np.expand_dims(melspec, axis=-1)\n",
    "        feature = model.predict(melspec)\n",
    "        features.append(feature.flatten())\n",
    "    return np.array(features)\n",
    "\n",
    "X_train_features = extract_features(X_train, vggish_model)\n",
    "X_test_features = extract_features(X_test, vggish_model)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train_features.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_features, y_train, epochs=100, batch_size=32, validation_data=(X_test_features, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test_features, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lewagon)",
   "language": "python",
   "name": "lewagon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
